{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Beating Classifiers\n",
      "\n",
      "### Please Note\n",
      "\n",
      "I am not a spammer! I've studied machine learning and classification over the last year and became interested in the topic. I've always thought that a good way to learn about how something works is to break it. The desire to break classification systems in order to learn about them is what drove me to work on this project. \n",
      "\n",
      "## Introduction\n",
      "\n",
      "Imagine we are sending messages to a classifier for which we can only observe the input features and the classification result. For example: \n",
      "\n",
      "- Sending messages to an email inbox where they are filtered by a spam classifier. \n",
      "- Asking bots to scrape a website where they are filtered by a bot detection algorithm. \n",
      "\n",
      "In these cases we can have access to the input data and can find some way of getting the classification result.\n",
      "\n",
      "Using this information, we want to devise an method that can beat the classifier. \"Beating the classifier\" means crafting feature vectors which:\n",
      "\n",
      "- Satisify some requirements we define, and \n",
      "- Are not rejected by the classifier\n",
      "\n",
      "## Preliminaries\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "- Familiarity with machine learning techniques and terminology, e.g. \"classifier\", \"training set\", etc. \n",
      "- Familiarity with the Logistical Regresssion Classifier specifically, the sigmoid function, log-loss scoring, etc. \n",
      "\n",
      "### Definitions\n",
      "\n",
      "- The Classifier: The classifier we are trying to beat\n",
      "- The Anti-Classifier: The algorithm we write to try and beat the classifier\n",
      "- Message: The raw message / object that we is constructed by the anti-classifier and sent to the classifier\n",
      "- Feature Vector: A vector of features extracted from the message\n",
      "- Feature Specificiations: The data type, max / min value and name of each variable entry in the feature vector\n",
      "- Feature Contraints: A set of requirements we want our feature vector to satisfy while still passing through the classifier\n",
      "\n",
      "## General Approach\n",
      "\n",
      "We tackle this problem by building our own anti-classifier which learns the behaviour of the target classifier. By using the information in the decision function of this anti-classifier we should be able craft feature vectors which we expect to pass through the classifier. \n",
      "\n",
      "We proceed as follows:\n",
      "\n",
      "- Stage One: Train the Anti-Classifier\n",
      "\n",
      "    1. Define feature specifications, i.e. name, max value, min value, data type for each feature used by the classifier\n",
      "    1. Randomly generate a set of intial feature vectors that conform to the specifications\n",
      "    1. Create a logisitical regression classifier to use as our anti-classifier. \n",
      "    1. Create messages out of the randomly generated set of feature vectors and send these messages to the classifier \n",
      "    1. Record the result for each message\n",
      "    1. Use the results to train the anti-classifier\n",
      "\n",
      "- Stage Two: Use the Anti-Classifier\n",
      "    \n",
      "    1. Create feature constraints, i.e. a range of values that features must fall into\n",
      "    1. Generate a feature vector that minimizes the decision function of the anti-classifier under those contraints\n",
      "    1. Output the result\n",
      "\n",
      "The result is a feature vector which we expect to not be caught by the classifier. \n",
      "\n",
      "### Simplifications\n",
      "\n",
      "One of the most complex and error-prone portions of this approach would be a translation layer between feature vectors and messages (Stage 1, step 4, above). A feature vector would go through the following transformations:\n",
      "\n",
      "    Anti-Classifier Features --(Anti-Classifier Translation)--> Messages --(Classifier Translation)--> Classifier Features\n",
      "\n",
      "There are several hurdles to overcome:\n",
      "\n",
      "- We are not allowed to know the Classifier Translation step\n",
      "- The Anti-Classifier translation layer is specific to each use case\n",
      "- We risk missing features that are significant to the classifier\n",
      "\n",
      "For the purposes of this document we ignore the translation layer and concentrate on the core algorithm. Do do this, we simply grant the the anti-classifier access to the feature specifications of the classifier. The message-passing therefore takes the form:\n",
      "\n",
      "    Anti-Classifier Features --> Classifier Features\n",
      "\n",
      "The features do not undergo any transformation between the two components. However we avoid sharing too much information by not giving the anti-classifier access to the classifier parameters or the classifier training set. \n",
      "\n",
      "### Test Data\n",
      "\n",
      "For this project we use the (Spambase Data Set)[https://archive.ics.uci.edu/ml/datasets/Spambase] from the (UCI Machine Learning Repository)[https://archive.ics.uci.edu/ml/index.html]. \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Algorithm\n",
      "\n",
      "The code for the this algorithm can be found in the `src/` directory. \n",
      "\n",
      "### Initialization \n",
      "\n",
      "We begin by loading test data using `src/data.py`.  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src import data\n",
      "xtrain, xtest, ytrain, ytest = data.load_spambase_test_train()\n",
      "print(\"Number of features: {0}\".format(len(xtrain.columns)))\n",
      "xtrain[xtrain.columns[:5]].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 57\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>capital_run_length_average</th>\n",
        "      <th>capital_run_length_longest</th>\n",
        "      <th>capital_run_length_total</th>\n",
        "      <th>char_freq_!</th>\n",
        "      <th>char_freq_#</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>3082.000000</td>\n",
        "      <td>3082.000000</td>\n",
        "      <td>3082.000000</td>\n",
        "      <td>3082.000000</td>\n",
        "      <td>3082.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>4.899553</td>\n",
        "      <td>52.884491</td>\n",
        "      <td>289.825438</td>\n",
        "      <td>0.276092</td>\n",
        "      <td>0.050973</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>25.285658</td>\n",
        "      <td>216.191784</td>\n",
        "      <td>609.223593</td>\n",
        "      <td>0.906813</td>\n",
        "      <td>0.496842</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>1.576250</td>\n",
        "      <td>6.000000</td>\n",
        "      <td>34.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>2.275500</td>\n",
        "      <td>14.000000</td>\n",
        "      <td>93.500000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>3.706750</td>\n",
        "      <td>43.000000</td>\n",
        "      <td>267.000000</td>\n",
        "      <td>0.326000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>667.000000</td>\n",
        "      <td>9989.000000</td>\n",
        "      <td>10062.000000</td>\n",
        "      <td>32.478000</td>\n",
        "      <td>19.829000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "       capital_run_length_average  capital_run_length_longest  \\\n",
        "count                 3082.000000                 3082.000000   \n",
        "mean                     4.899553                   52.884491   \n",
        "std                     25.285658                  216.191784   \n",
        "min                      1.000000                    1.000000   \n",
        "25%                      1.576250                    6.000000   \n",
        "50%                      2.275500                   14.000000   \n",
        "75%                      3.706750                   43.000000   \n",
        "max                    667.000000                 9989.000000   \n",
        "\n",
        "       capital_run_length_total  char_freq_!  char_freq_#  \n",
        "count               3082.000000  3082.000000  3082.000000  \n",
        "mean                 289.825438     0.276092     0.050973  \n",
        "std                  609.223593     0.906813     0.496842  \n",
        "min                    1.000000     0.000000     0.000000  \n",
        "25%                   34.000000     0.000000     0.000000  \n",
        "50%                   93.500000     0.000000     0.000000  \n",
        "75%                  267.000000     0.326000     0.000000  \n",
        "max                10062.000000    32.478000    19.829000  "
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`xtrain` and `ytrain` are the feature vectors and classification labels for the training set. `xtest` and `ytest` make up the tests set. There are 57 features in total. \n",
      "\n",
      "We can now initialize and train one of the classifiers from `src/classifier.py`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src import classifier\n",
      "logistic = classifier.logistic()\n",
      "logistic.fit(xtrain, ytrain)\n",
      "logistic.score(xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.92626728110599077"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The trained classfier has a precision of 93% on the test set. \n",
      "\n",
      "To create an anticlassifier we need the specifications which define each of the features in the vectors we will generate. The file `src/features.py` examines the spambase training set and generates these specifications for us:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "from src import features\n",
      "feature_specs = features.SPAMBASE_FEATURE_SPECS\n",
      "pprint(feature_specs[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The feature specs define maximum values, minimum values, and data types for each feature. \n",
      "\n",
      "With this data in hand we can create the anti-classifier using the file `src/anticlassifier.py`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src import anticlassifier\n",
      "anti = anticlassifier.AntiClassifier(logistic, feature_specs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Upon initialization the `AntiClassifier` object randomly creates 10,000 feature vectors using the provided specifications. It sends these feature vectors to the classifier and records the result. It then uses this information to train it's own anti-classifier. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "anti.anticlassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "Pipeline(steps=[('transform', Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))])), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0))])"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The parameters of this anti-classifier can be examined:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "anti._lg_coefs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([-0.59371721,  5.21976853,  0.66563191,  0.68231796,  3.40803816,\n",
        "        2.55593076, -0.09321724, -0.63665364, -1.04903439,  1.05073332,\n",
        "       -0.42083714,  1.42649124, -1.26482602,  0.15820815, -2.25866321,\n",
        "        0.26896796, -0.14949918,  0.36958354,  0.19165077,  0.52949179,\n",
        "       -1.55144751,  1.33183915, -2.91742024, -1.45333764, -0.23731202,\n",
        "       -2.01262521,  0.05247497,  0.43473568,  1.8813781 , -3.20101345,\n",
        "       -2.58961489, -0.94915857,  0.51159239, -1.35074572, -0.89009403,\n",
        "        0.05629574, -0.14024281, -1.6227735 ,  0.3538652 ,  0.21628842,\n",
        "       -0.24829001,  0.27806072,  0.25327916, -0.49820693,  0.02003644,\n",
        "       -0.754923  , -2.05029181, -1.52258117, -0.05179178,  1.35112996,\n",
        "        0.03135411, -0.41025854,  0.28805579, -0.08992643, -0.05382914,\n",
        "        0.0909433 ,  0.17586318])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generating Feature Vectors\n",
      "\n",
      "The `get()` method is used to generate a feature vector which minimizes the anti-classifier's decision function under a set of provided constraints. We can generate such feature vector with no constraints:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v = anti.get([])\n",
      "print(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  4.78063014e+02   6.99400000e+03   8.66700000e+03   2.02628232e+01\n",
        "   8.14344663e+00   2.84812793e+00   9.64759029e+00   3.77544424e+00\n",
        "   3.16802839e+00   3.81283307e+00   4.71189292e+00   3.83884781e+00\n",
        "   7.21977563e-01   1.29492623e+00   6.51781872e+00   3.90789400e-01\n",
        "   6.72931367e+00   2.22965341e+00   3.11304362e-01   9.01342249e-01\n",
        "   4.94447305e+00   1.08683822e+01   4.17139108e+00   1.26235332e+01\n",
        "   2.11297064e+00   8.31262543e+00   4.08096761e+00   2.13697454e+00\n",
        "   1.56711451e+00   2.09573500e+01   1.28400164e+01   4.93735357e+00\n",
        "   6.70799474e-01   5.01157055e+00   5.14033704e+00   1.06432832e+01\n",
        "   5.21134006e-01   5.86555435e+00   1.17706573e+00   1.60955276e+00\n",
        "   2.29982482e+00   5.60210861e+00   4.01366653e+00   7.26823889e+00\n",
        "   4.05715493e+00   7.66174828e+00   2.42419077e+00   1.59218259e+01\n",
        "   2.00029901e+00   4.33470240e+00   7.46775675e+00   1.20833876e+00\n",
        "   9.05267953e-01   1.16542442e+00   7.93817589e-01   1.70779055e+00\n",
        "   8.08166231e+00]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By passing this generated feature vector to the classifier we see that it passes through, as expected (a zero value indicates \"not-spam\" in the spambase data set). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logistic.predict(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([0])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also provide a set of constraints to get a different feature vector. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pprint(features.SPAMBASE_CONSTRAINTS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'fun': <function <lambda> at 0x10b8f3848>,\n",
        "  'init': <function <lambda> at 0x10b8f3f50>,\n",
        "  'name': 'capital_run_length_average_gt_10',\n",
        "  'type': 'ineq'},\n",
        " {'fun': <function <lambda> at 0x10b8f35f0>,\n",
        "  'init': <function <lambda> at 0x10b8f3ed8>,\n",
        "  'name': 'capital_run_length_longest_gt_5',\n",
        "  'type': 'ineq'}]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v = anti.get(features.SPAMBASE_CONSTRAINTS)\n",
      "print(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  2.41644276e+03   1.94049558e+04   7.92498928e+03   1.62032033e+01\n",
        "   9.89032580e+00   2.98960040e+00   7.82272721e+00   4.12164493e+00\n",
        "   3.80826494e+00   2.73384633e+00   4.95055012e+00   2.13293210e+01\n",
        "   2.97581904e+00   4.17654396e+00   1.44486798e+01   2.37157579e+00\n",
        "   7.53820776e+00   1.42940296e+00   2.74299271e+00   5.81564573e+00\n",
        "   9.72164843e+00   1.16599720e+01   5.50516376e+00   1.15546444e+01\n",
        "   2.55653213e+00   1.38904801e+01   3.26372455e+00   8.51246630e+00\n",
        "   1.61002119e+01   3.25900854e+01   1.52470017e+01   4.84347169e+00\n",
        "   5.58521291e+00   8.42370494e+00   3.38326910e+00   1.09174965e+01\n",
        "   2.31010606e+00   7.33797663e+00   1.17838709e+01   1.94612349e+00\n",
        "   2.54000431e+00   8.87055256e+00   3.19865333e+00   4.61598440e+00\n",
        "   4.25599385e+00   1.14099900e+01   1.14288411e+01   1.62505688e+01\n",
        "   1.37362463e+00   3.65855969e+00   9.88862021e+00   1.72819962e+00\n",
        "   2.39753587e+00   3.10433772e+00   5.00818304e+00   9.32712949e+00\n",
        "   1.00958850e+01]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logistic.predict(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([0])"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Testing the Anti-Classifier\n",
      "\n",
      "To test the performance of the anti-classifier we proceed as follows:\n",
      "\n",
      "- Determine the most significant features in prediction\n",
      "- Constrain these features one by one and test how well the anti-classifier performs\n",
      "- Constraints can maximize or minimize features\n",
      "\n",
      "This process is implemented in the `src/evaluate.py` file. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src import evaluate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most significant features are determined by examining the p-values of an ANOVA hypothesis test. These features can then constrained to their maximum and minimum values to determine how well the anti-classifier performs. \n",
      "\n",
      "We can perform this test for several different target classifiers. \n",
      "\n",
      "### Logistical Regression Classifier\n",
      "\n",
      "The logistical regression classifier was already initialized, above. To test it we pass it to the `evaluate.evaluate()` function. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perf_max_constraint = evaluate.evaluate(logistic, constrain=\"max\")\n",
      "perf_min_constraint = evaluate.evaluate(logistic, constrain=\"min\")\n",
      "perf_max_constraint.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>significant_features_constrained</th>\n",
        "      <th>anticlassifier_score</th>\n",
        "      <th>classifier_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0</td>\n",
        "      <td>0.979</td>\n",
        "      <td>0.926267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>0.656</td>\n",
        "      <td>0.926267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>2</td>\n",
        "      <td>0.286</td>\n",
        "      <td>0.926267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>3</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.926267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>4</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.926267</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "   significant_features_constrained  anticlassifier_score  classifier_score\n",
        "1                                 0                 0.979          0.926267\n",
        "2                                 1                 0.656          0.926267\n",
        "3                                 2                 0.286          0.926267\n",
        "4                                 3                 0.000          0.926267\n",
        "5                                 4                 0.000          0.926267"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(perf_max_constraint[\"significant_features_constrained\"], perf_max_constraint[\"anticlassifier_score\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10e57af50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbERFXUTERlTURURsREVdRMRG/h9T4ithhrBkOwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10bc28e50>"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By maximizing just 3 of the 57 features used by the classifier we become completely unable to generate vectors which are accepted. Most machine-learning problem spaces have only a few features which dominate the output so this behaviour is expected. \n",
      "\n",
      "We can turn this around by minimizing the significant features instead of maximizing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(perf_min_constraint[\"significant_features_constrained\"], perf_min_constraint[\"anticlassifier_score\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10b5d3590>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10b3fe150>"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Naive Bayes Classifier\n",
      "\n",
      "Next we target a naive bayes classifier and perform the same test. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bayes = classifier.naive_bayes()\n",
      "bayes.fit(xtrain, ytrain)\n",
      "print(bayes.score(xtest, ytest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.810401579987\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perf_max_constraint = evaluate.evaluate(bayes, constrain=\"max\")\n",
      "perf_min_constraint = evaluate.evaluate(bayes, constrain=\"min\")\n",
      "perf_max_constraint.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>significant_features_constrained</th>\n",
        "      <th>anticlassifier_score</th>\n",
        "      <th>classifier_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>5</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>6</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>7</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>8</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>9</td>\n",
        "      <td>1</td>\n",
        "      <td>0.810402</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "    significant_features_constrained  anticlassifier_score  classifier_score\n",
        "1                                  0                     1          0.810402\n",
        "2                                  1                     1          0.810402\n",
        "3                                  2                     1          0.810402\n",
        "4                                  3                     1          0.810402\n",
        "5                                  4                     1          0.810402\n",
        "6                                  5                     1          0.810402\n",
        "7                                  6                     1          0.810402\n",
        "8                                  7                     1          0.810402\n",
        "9                                  8                     1          0.810402\n",
        "10                                 9                     1          0.810402"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(perf_max_constraint[\"significant_features_constrained\"], perf_max_constraint[\"anticlassifier_score\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10eeb45d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFLpJREFUeJzt3X9MVff9x/HXtdCkw05No9d5722hgHgReoWo/GULa50L\niaS2LMHaiUAd0RmxaZa4P5bCP07TJsZK/1CntiQN+sfMpM3t/YMul7i6G5fCWgNkQuM1915XoxuX\nxukK3JzvH+57HSL3egU9nZ/nI7mRc88P3vemfXI8l9M6LMuyBAB4pM2xewAAwINH7AHAAMQeAAxA\n7AHAAMQeAAxA7AHAAGlj39jYKKfTqdLS0mm32blzpwoLC+Xz+dTX15d8Ph6Pq7a2Vl6vV8XFxQqF\nQrMzNQAgI2lj39DQoEAgMO16v9+v4eFhDQ0N6fDhw9q2bVtyXUtLi6qrqzU4OKivvvpKXq93dqYG\nAGQkbezXrFmjBQsWTLu+q6tL9fX1kqSKigrF43FduXJFo6OjOnPmjBobGyVJWVlZmjdv3iyNDQDI\nxIyv2cdiMXk8nuSy2+1WNBrVxYsXtXDhQjU0NKi8vFxbt27VjRs3ZvrtAAD3YVY+oL3zv7jgcDg0\nMTGh3t5ebd++Xb29vcrJydHevXtn49sBADKUNdMDuFwuRSKR5HI0GpXL5ZJlWXK73Vq1apUkqba2\n9q6xLygo0Ndffz3TMQDAKPn5+RoeHr7n7Wd8Zl9TU6OOjg5JUigU0vz58+V0OrV48WJ5PB5duHBB\nktTd3a3ly5dP2f/rr7+WZVk8LEtvv/227TN8Xx68F7wXvBepH5meJKc9s9+4caN6enp07do1eTwe\ntbW1aXx8XJLU3Nys6upq+f1+FRQUKCcnR8ePH0/ue/DgQW3atEljY2PKz8+ftA4A8PCkjX1nZ2fa\ng7S3t9/1eZ/Pp7/85S+ZTwUAmFXcQfs9UllZafcI3xu8F7fxXtzGe3H/HJZl2fo/L3E4HLJ5BAD4\nn5NpOzmzBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsA\nMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACxBwADEHsAMACx\nBwADEHsAMEDa2Dc2NsrpdKq0tHTabXbu3KnCwkL5fD719fVNWpdIJFRWVqb169fPfFoAwH1JG/uG\nhgYFAoFp1/v9fg0PD2toaEiHDx/Wtm3bJq0/cOCAiouL5XA4Zj4tAOC+pI39mjVrtGDBgmnXd3V1\nqb6+XpJUUVGheDyuK1euSJKi0aj8fr/eeOMNWZY1SyMDADI142v2sVhMHo8nuex2uxWLxSRJb775\npt555x3NmcNHAwBgp1mp8J1n7ZZl6ZNPPtGiRYtUVlbGWT0A2CxrpgdwuVyKRCLJ5Wg0KpfLpd//\n/vfq6uqS3+/Xv//9b3377bfavHmzOjo6phyjtbU1+XVlZaUqKytnOhYAPFKCwaCCweB97++w7uG0\nOxwOa/369Tp//vyUdX6/X+3t7fL7/QqFQtq1a5dCodCkbXp6evTuu+/q448/njqAw8GZPwBkKNN2\npj2z37hxo3p6enTt2jV5PB61tbVpfHxcktTc3Kzq6mr5/X4VFBQoJydHx48fn3YwAIA97unM/oEO\nwJk9AGQs03byazIAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYA\nYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYABi\nDwAGIPYAYABiDwAGIPYAYABiDwAGIPYAYIC0sW9sbJTT6VRpaem02+zcuVOFhYXy+Xzq6+uTJEUi\nEVVVVWn58uUqKSnRe++9N3tTAwAykjb2DQ0NCgQC0673+/0aHh7W0NCQDh8+rG3btkmSsrOztX//\nfvX39ysUCun999/X4ODg7E0OALhnaWO/Zs0aLViwYNr1XV1dqq+vlyRVVFQoHo/rypUrWrx4sVas\nWCFJmjt3rrxery5fvjxLYwMAMjHja/axWEwejye57Ha7FY1GJ20TDofV19enioqKmX47AMB9yJqN\ng1iWNWnZ4XAkv75+/bpqa2t14MABzZ079677t7a2Jr+urKxUZWXlbIwFAI+MYDCoYDB43/vPOPYu\nl0uRSCS5HI1G5XK5JEnj4+N69dVX9frrr+vll1+e9hj/HXsAwFR3ngi3tbVltP+ML+PU1NSoo6ND\nkhQKhTR//nw5nU5ZlqWmpiYVFxdr165dM/02AIAZcFh3XoO5w8aNG9XT06Nr167J6XSqra1N4+Pj\nkqTm5mZJ0o4dOxQIBJSTk6Pjx4+rvLxcf/rTn/T888/rueeeS17W+e1vf6uf/vSnkwdwOKZcBgIA\npJZpO9PG/kEj9gCQuUzbyR20AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAA\nYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8A\nBiD2AGAAYg8ABiD2AGAAYg8ABiD2AGAAYg8ABkgb+8bGRjmdTpWWlk67zc6dO1VYWCifz6e+vr7k\n84FAQMuWLVNhYaH27ds3OxMDADKWNvYNDQ0KBALTrvf7/RoeHtbQ0JAOHz6sbdu2SZISiYR27Nih\nQCCggYEBdXZ2anBwcPYmBwDcs7SxX7NmjRYsWDDt+q6uLtXX10uSKioqFI/H9c033+jcuXMqKChQ\nbm6usrOzVVdXp9OnT8/e5ACAezbja/axWEwejye57Ha7FYvFdPny5bs+DwB4+LJm4yCWZc1of4ej\n9b+WKv/zAADcFvzP4/7MOPYul0uRSCS5HI1G5Xa7NT4+Pun5SCQit9t912NYVutMxwCAR1yl/vtE\n2OFoy2jvGV/GqampUUdHhyQpFApp/vz5cjqdWrlypYaGhhQOhzU2NqaTJ0+qpqZmpt8OAHAf0p7Z\nb9y4UT09Pbp27Zo8Ho/a2to0Pj4uSWpublZ1dbX8fr8KCgqUk5Oj48eP3zpwVpba29u1bt06JRIJ\nNTU1yev1PthXAwC4K4c10wvuMx3A4ZjxNX8AME2m7eQOWgAwALEHAAMQewAwALEHAAMQewAwALEH\nAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQ\newAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAOkjX0gENCyZctUWFio\nffv2TVk/MjKiDRs2yOfzqaKiQv39/cl1+/fvV0lJiUpLS/Xaa6/pu+++m93pAQD3JGXsE4mEduzY\noUAgoIGBAXV2dmpwcHDSNnv27FF5ebm+/PJLdXR0qKWlRZIUi8V08OBBffHFFzp//rwSiYROnDjx\n4F4JAGBaKWN/7tw5FRQUKDc3V9nZ2aqrq9Pp06cnbTM4OKiqqipJUlFRkcLhsK5evSpJmpiY0I0b\nN5J/ulyuB/QyAACppIx9LBaTx+NJLrvdbsVisUnb+Hw+nTp1StKtHw6XLl1SNBqVy+XSW2+9paef\nflpLlizR/Pnz9dJLLz2AlwAASCcr1UqHw5H2ALt371ZLS4vKyspUWlqqsrIyPfbYYxoZGVFXV5fC\n4bDmzZunn/3sZ/roo4+0adOmKcdobW1Nfl1ZWanKysqMXwgAPMqCwaCCweB9758y9i6XS5FIJLkc\niUTkdrsnbfPkk0/q2LFjyeW8vDw9++yz+vTTT5WXl6ennnpKkvTKK6/o7NmzaWMPAJjqzhPhtra2\njPZPeRln5cqVGhoaUjgc1tjYmE6ePKmamppJ24yOjmpsbEySdOTIEb3wwguaO3eunnnmGYVCId28\neVOWZam7u1vFxcUZDQcAmB0pz+yzsrLU3t6udevWKZFIqKmpSV6vV4cOHZIkNTc3a2BgQFu2bJHD\n4VBJSYmOHj0qSVq9erVqa2tVXl6urKwslZeX6xe/+MWDf0UAgCkclmVZtg7gcMjmEQDgf06m7eQO\nWgAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAw\nALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEHAAMQewAwALEH\nAAMQewAwALEHAAOkjX0gENCyZctUWFioffv2TVk/MjKiDRs2yOfzqaKiQv39/cl18XhctbW18nq9\nKi4uVigUmt3pAQD3xGFZljXdykQioaKiInV3d8vlcmnVqlXq7OyU1+tNbvOrX/1KP/zhD/Wb3/xG\nf/vb3/TLX/5S3d3dkqT6+nq98MILamxs1MTEhP71r39p3rx5kwdwOJRiBADAXWTazpRn9ufOnVNB\nQYFyc3OVnZ2turo6nT59etI2g4ODqqqqkiQVFRUpHA7r6tWrGh0d1ZkzZ9TY2ChJysrKmhJ6AMDD\nkTL2sVhMHo8nuex2uxWLxSZt4/P5dOrUKUm3fjhcunRJ0WhUFy9e1MKFC9XQ0KDy8nJt3bpVN27c\neAAvAQCQTsrYOxyOtAfYvXu34vG4ysrK1N7errKyMj322GOamJhQb2+vtm/frt7eXuXk5Gjv3r2z\nNjgA4N5lpVrpcrkUiUSSy5FIRG63e9I2Tz75pI4dO5ZczsvL07PPPqvr16/L7XZr1apVkqTa2tpp\nY9/a2pr8urKyUpWVlZm+DgB4pAWDQQWDwfveP+UHtBMTEyoqKtJnn32mJUuWaPXq1VM+oB0dHdUT\nTzyhxx9/XEeOHNHnn3+uDz74QJL0/PPP63e/+52WLl2q1tZW3bx5c8pv9PABLQBkLtN2pjyzz8rK\nUnt7u9atW6dEIqGmpiZ5vV4dOnRIktTc3KyBgQFt2bJFDodDJSUlOnr0aHL/gwcPatOmTRobG1N+\nfr6OHz9+ny8LADATKc/sH8oAnNkDQMZm9VcvAQCPBmIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBg\nAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIP\nAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAYg9gBgAGIPAAZIG/tAIKBly5apsLBQ+/btm7J+\nZGREGzZskM/nU0VFhfr7+yetTyQSKisr0/r162dvagBARlLGPpFIaMeOHQoEAhoYGFBnZ6cGBwcn\nbbNnzx6Vl5fryy+/VEdHh1paWiatP3DggIqLi+VwOGZ/+kdMMBi0e4TvDd6L23gvbuO9uH8pY3/u\n3DkVFBQoNzdX2dnZqqur0+nTpydtMzg4qKqqKklSUVGRwuGwrl69KkmKRqPy+/164403ZFnWA3oJ\njw7+Qb6N9+I23ovbeC/uX8rYx2IxeTye5LLb7VYsFpu0jc/n06lTpyTd+uFw6dIlRaNRSdKbb76p\nd955R3Pm8NEAANgpZYXv5dLL7t27FY/HVVZWpvb2dpWVlWnOnDn65JNPtGjRIpWVlXFWDwB2s1L4\n85//bK1bty65vGfPHmvv3r2pdrFyc3Otb7/91vr1r39tud1uKzc311q8eLH1gx/8wPr5z38+Zfv8\n/HxLEg8ePHjwyOCRn5+fssV3clgpTrsnJiZUVFSkzz77TEuWLNHq1avV2dkpr9eb3GZ0dFRPPPGE\nHn/8cR05ckSff/65Pvjgg0nH6enp0bvvvquPP/54um8FAHiAslKuzMpSe3u71q1bp0QioaamJnm9\nXh06dEiS1NzcrIGBAW3ZskUOh0MlJSU6evToXY/Fb+MAgH1SntkDAB4Ntv6aTLobtkwRiURUVVWl\n5cuXq6SkRO+9957dI9mOm/Fuicfjqq2tldfrVXFxsUKhkN0j2Wb//v0qKSlRaWmpXnvtNX333Xd2\nj/TQNDY2yul0qrS0NPncP//5T61du1ZLly7VT37yE8Xj8ZTHsC3293LDlimys7O1f/9+9ff3KxQK\n6f333zf2vfh/3Ix3S0tLi6qrqzU4OKivvvpq0udlJonFYjp48KC++OILnT9/XolEQidOnLB7rIem\noaFBgUBg0nN79+7V2rVrdeHCBb344ovau3dvymPYFvt7uWHLFIsXL9aKFSskSXPnzpXX69Xly5dt\nnso+3Ix3y+joqM6cOaPGxkZJtz5Dmzdvns1T2WdiYkI3btxI/ulyuewe6aFZs2aNFixYMOm5rq4u\n1dfXS5Lq6+v1hz/8IeUxbIv9vdywZaJwOKy+vj5VVFTYPYptuBnvlosXL2rhwoVqaGhQeXm5tm7d\nqhs3btg9li1cLpfeeustPf3001qyZInmz5+vl156ye6xbHXlyhU5nU5JktPp1JUrV1Jub9u/Tab/\n9fxurl+/rtraWh04cEBz5861exxbcDPebRMTE+rt7dX27dvV29urnJyctH9Vf1SNjIyoq6tL4XBY\nly9f1vXr1/XRRx/ZPdb3hsPhSNtU22LvcrkUiUSSy5FIRG63265xbDc+Pq5XX31Vr7/+ul5++WW7\nx7HN2bNn1dXVpby8PG3cuFF//OMftXnzZrvHsoXb7Zbb7daqVaskSbW1tert7bV5Knt0d3crLy9P\nTz31lLKysvTKK6/o7Nmzdo9lK6fTqW+++UaS9Pe//12LFi1Kub1tsV+5cqWGhoYUDoc1NjamkydP\nqqamxq5xbGVZlpqamlRcXKxdu3bZPY6t9uzZo0gkoosXL+rEiRP68Y9/rI6ODrvHssXixYvl8Xh0\n4cIFSbeCt3z5cpunssczzzyjUCikmzdvyrIsdXd3q7i42O6xbFVTU6MPP/xQkvThhx+mP0nM6H7b\nWeb3+62lS5da+fn51p49e+wcxVZnzpyxHA6H5fP5rBUrVlgrVqywPv30U7vHsl0wGLTWr19v9xi2\n+utf/2qtXLnSeu6556wNGzZY8Xjc7pFs8/bbb1vLli2zSkpKrM2bN1tjY2N2j/TQ1NXVWT/60Y+s\n7Oxsy+12W8eOHbP+8Y9/WC+++KJVWFhorV271hoZGUl5DG6qAgADmP3rDgBgCGIPAAYg9gBgAGIP\nAAYg9gBgAGIPAAYg9gBgAGIPAAb4Py4MVvrK781QAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10b9288d0>"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case it appears that the naive bayes classifier's precision was so low that the anti-classifier was always able to generate a vector that was accepted. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Support Vector Machine\n",
      "\n",
      "Finally we target a support vector machine. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import imp\n",
      "imp.reload(anticlassifier)\n",
      "imp.reload(evaluate)\n",
      "imp.reload(classifier)\n",
      "\n",
      "svm = classifier.svm()\n",
      "svm.fit(xtrain, ytrain)\n",
      "print(svm.score(xtest, ytest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.932192231731\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perf_max_constraint = evaluate.evaluate(svm, constrain=\"max\")\n",
      "perf_min_constraint = evaluate.evaluate(svm, constrain=\"min\")\n",
      "perf_max_constraint.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-49-753286351a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperf_max_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mperf_min_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperf_max_constraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/matthewfournier/personal/beating_classifiers/src/evaluate.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(classifier, constrain)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# base case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     p, r = anticlassifier_precision(\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/matthewfournier/personal/beating_classifiers/src/evaluate.pyc\u001b[0m in \u001b[0;36manticlassifier_precision\u001b[0;34m(classifier, feature_specs, constraints, x, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manticlassifier_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0manti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manticlassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAntiClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     record = pd.DataFrame(\n\u001b[1;32m     41\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_specs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"classifier_predict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/matthewfournier/personal/beating_classifiers/src/anticlassifier.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, classifier, feature_specs, prepare)\u001b[0m\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/matthewfournier/personal/beating_classifiers/src/anticlassifier.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, num_points)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# fit the anticlassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manticlassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# used to periodically update / retrain the anticlassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 )\n\u001b[1;32m   1038\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[1;32m    807\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    808\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(perf_max_constraint[\"significant_features_constrained\"], perf_max_constraint[\"anticlassifier_score\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(perf_min_constraint[\"significant_features_constrained\"], perf_min_constraint[\"anticlassifier_score\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "## Conclusions\n",
      "\n",
      "\n",
      "## Appendix\n",
      "\n",
      "### Feature -> Message Translation\n",
      "\n",
      "Would the `feature -> message` translation layer in the anti-classifier need to match the `message -> feature` extraction in the classifier?\n",
      "\n",
      "This part I'm not sure about.\n",
      "\n",
      "`anti-feature space -> message -> feature space`\n",
      "\n",
      "We know nothing about the second transform. We can't gaurantee anything about the composite transform. We might be working on a different basis, a different number of dimensions, etc, from the classifier feature space. We may not even be able to influence many of the features that the classifier depends on. \n",
      "\n",
      "If we need hundreds of features for our anti-classifier then we'll need to write a translation layer, by hand, that accounts for those hundreds of features. On the other hand, in most applications classifiers depend on a small number of features that contribute most strongly to the classification result, so even if the classifier uses hundreds we may only need to consider a handful of them. \n",
      "\n",
      "If we keep looking for an effective set of classifier features we will find them eventually. It may not always be possible, or it may take a long time, but it is possible in principle. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}